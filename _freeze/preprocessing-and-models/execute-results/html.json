{
  "hash": "92d7965a92bd9903a5aaa01cfb5c5be3",
  "result": {
    "markdown": "# Examples of Preprocessing and Models\n\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction \n\nThe `epipredict` package utilizes the `tidymodels` framework, namely \n[`{recipes}`](https://recipes.tidymodels.org/) for \n[dplyr](https://dplyr.tidyverse.org/)-like pipeable sequences \nof feature engineering and [`{parsnip}`](https://parsnip.tidymodels.org/) for a \nunified interface to a range of models. \n\n`epipredict` has additional customized feature engineering and preprocessing \nsteps, such as `step_epi_lag()`, `step_population_scaling()`, \n`step_epi_naomit()`. They can be used along with \nsteps from the `{recipes}` package for more feature engineering. \n\nIn this vignette, we will illustrate some examples of how to use `epipredict`\nwith `recipes` and `parsnip` for different purposes of epidemiological forecasting.\nWe will focus on basic autoregressive models, in which COVID cases and \ndeaths in the near future are predicted using a linear combination of cases and \ndeaths in the near past.\n\nThe remaining vignette will be split into three sections. The first section, we \nwill use a Poisson regression to predict death counts. In the second section,\nwe will use a linear regression to predict death rates. Last but not least, we\nwill create a classification model for hotspot predictions. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-2_77160893bd0d6d0125c95334440bfe94'}\n\n```{.r .cell-code}\nlibrary(epidatr)\nlibrary(epiprocess)\nlibrary(epipredict)\nlibrary(recipes)\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(poissonreg)\n```\n:::\n\n\n## Poisson Regression \n\nDuring COVID-19, the U.S. Centers for Disease Control and Prevention (CDC) collected\nmodels\nand forecasts to characterize the state of an outbreak and its course. They use\nit to inform public health decision makers on potential consequences of \ndeploying control measures.\n\nOne of the outcomes that the CDC forecasts is [death counts from COVID-19](https://www.cdc.gov/coronavirus/2019-ncov/science/forecasting/forecasting-us.html).\nAlthough there are many state-of-the-art models, we choose to use Poisson \nregression, the textbook example for modeling count data, as an illustration\nfor using the `epipredict` package with other existing tidymodels packages. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/poisson-reg-data_6cde08a985a46a41745d8895f73e12bb'}\n\n```{.r .cell-code}\ngeos <- c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\nx <- covidcast(\n  data_source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  fetch() %>%\n  select(geo_value, time_value, cases = value)\n\ny <- covidcast(\n  data_source = \"jhu-csse\",\n  signals = \"deaths_incidence_num\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  fetch() %>%\n  select(geo_value, time_value, deaths = value)\n\ncounts_subset <- full_join(x, y, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()\n```\n:::\n\n\nThe `counts_subset` dataset comes from the `epidatr` package, and \ncontains the number of confirmed cases and deaths from June 4, 2021 to \nDec 31, 2021 in some U.S. states. \n\nWe wish to predict the 7-day ahead death counts with lagged cases and deaths.\nFurthermore, we will let each state be a dummy variable. Using differential \nintercept coefficients, we can allow for an intercept shift between states.\n\nOne possible model takes the form\n\\begin{aligned}\n\\log\\left( \\mu_{t+7} \\right) &{}= \\beta_0 + \\delta_1 s_{\\text{state}_1} +\n\\delta_2 s_{\\text{state}_2} + \\cdots +  \\nonumber \\\\ &\\quad\\beta_1 \\text{deaths}_{t} + \n\\beta_2 \\text{deaths}_{t-7}  + \\beta_3 \\text{cases}_{t} + \n\\beta_4 \\text{cases}_{t-7},\n\\end{aligned}\nwhere $\\mu_{t+7} = \\mathbb{E}(\\text{deaths}_{t+7})$, and $\\text{deaths}_{t+7}$\nis assumed to follow a Poisson distribution with mean $\\mu_{t+7}$;\n$s_{\\text{state}}$ are dummy variables for each state and take values of either\n0 or 1.\n\nPreprocessing steps will be performed to prepare the\ndata for model fitting. But before diving into them, it will be helpful to understand what `roles` are in the `recipes` framework. \n\n---\n\n#### Aside on `recipes` {.unnumbered}\n\n`recipes` can assign one or more roles to each column in the data. The roles \nare not restricted to a predefined set; they can be anything. \nFor most conventional situations, they are typically “predictor” and/or \n\"outcome\". Additional roles enable targeted `step_*()` operations on specific \nvariables or groups of variables.\n\nIn our case, the role `predictor` is given to explanatory variables on the\nright-hand side of the model (in the equation above). \nThe role `outcome` is the response variable \nthat we wish to predict. `geo_value` and `time_value` are predefined roles \nthat are unique to the `epipredict` package. Since we work with `epi_df` \nobjects, all datasets should have `geo_value` and `time_value` passed through\nautomatically with these two roles assigned to the appropriate columns in the data.\n \nThe `recipes` package also allows [manual alterations of roles](https://recipes.tidymodels.org/reference/roles.html) \nin bulk. There are a few handy functions that can be used together to help us \nmanipulate variable roles easily. \n\n> `update_role()` alters an existing role in the recipe or assigns an initial role \n> to variables that do not yet have a declared role.\n> \n> `add_role()` adds an additional role to variables that already have a role in \n> the recipe, without overwriting old roles.\n> \n> `remove_role()` eliminates a single existing role in the recipe.\n\n#### End aside {.unnumbered}\n\n---\n\nNotice in the following preprocessing steps, we used `add_role()` on \n`geo_value_factor` since, currently, the default role for it is `raw`, but\nwe would like to reuse this variable as a `predictor`.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-3_260ec0fe51f37d8f03989ee6d1dcb8e9'}\n\n```{.r .cell-code}\ncounts_subset <- counts_subset %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  as_epi_df()\n\nepi_recipe(counts_subset)\n\nr <- epi_recipe(counts_subset) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  ## Occasionally, data reporting errors / corrections result in negative\n  ## cases / deaths\n  step_mutate(cases = pmax(cases, 0), deaths = pmax(deaths, 0)) %>%\n  step_epi_lag(cases, deaths, lag = c(0, 7)) %>%\n  step_epi_ahead(deaths, ahead = 7, role = \"outcome\") %>%\n  step_epi_naomit()\n```\n:::\n\n\nAfter specifying the preprocessing steps, we will use the `parsnip` package for\nmodeling and producing the prediction for death count, 7 days after the\nlatest available date in the dataset. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-4_e3bc60e0fccb3312be42c7662017656d'}\n\n```{.r .cell-code}\nlatest <- get_test_data(r, counts_subset)\n\nwf <- epi_workflow(r, parsnip::poisson_reg()) %>%\n  fit(counts_subset)\n\npredict(wf, latest) %>% filter(!is.na(.pred))\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2023-06-07 11:06:22.428345\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred\n#> * <chr>     <date>     <dbl>\n#> 1 ca        2021-12-31 108. \n#> 2 fl        2021-12-31 270. \n#> 3 nj        2021-12-31  22.5\n#> 4 ny        2021-12-31  94.8\n#> 5 tx        2021-12-31  91.0\n```\n:::\n\n\nNote that the `time_value` corresponds to the last available date in the \ntraining set, **NOT** to the target date of the forecast \n(2022-01-07).\n\n\nLet's take a look at the fit:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-5_2d8210b1433516f95edf67a6c7b15c36'}\n\n```{.r .cell-code}\nextract_fit_engine(wf)\n#> \n#> Call:  stats::glm(formula = ..y ~ ., family = stats::poisson, data = data)\n#> \n#> Coefficients:\n#>         (Intercept)  geo_value_factor_fl  geo_value_factor_nj  \n#>           3.970e+00           -1.487e-01           -1.425e+00  \n#> geo_value_factor_ny  geo_value_factor_tx          lag_0_cases  \n#>          -6.865e-01            3.025e-01            1.339e-05  \n#>         lag_7_cases         lag_0_deaths         lag_7_deaths  \n#>           1.717e-06            1.731e-03            8.566e-04  \n#> \n#> Degrees of Freedom: 984 Total (i.e. Null);  976 Residual\n#> Null Deviance:\t    139600 \n#> Residual Deviance: 58110 \tAIC: 62710\n```\n:::\n\n\nAlternative forms of Poisson regression or particular computational approaches\ncan be applied via arguments to `parsnip::poisson_reg()` for some common\nsettings, and by using `parsnip::set_engine()` to use a specific Poisson\nregression engine and to provide additional engine-specific customization.\n\n\n\n## Linear Regression \n\nFor COVID-19, the CDC required submission of case and death count predictions. \nHowever, the Delphi Group preferred to train on rate data instead, because it \nputs different locations on a similar scale (eliminating the need for location-specific intercepts). \nWe can use a linear regression to predict the death rates and use state\npopulation data to scale the rates to counts.[^pois] We will do so using\n`layer_population_scaling()` from the `epipredict` package. (We could also use\n`step_population_scaling()` from the `epipredict` package to prepare rate data\nfrom count data in the preprocessing recipe.)\n\n[^pois]: We could continue with the Poisson model, but we'll switch to the Gaussian likelihood just for simplicity.\n\nAdditionally, when forecasts are submitted, prediction intervals should be \nprovided along with the point estimates. This can be obtained via postprocessing\nusing\n`layer_residual_quantiles()`. It is worth pointing out, however, that \n`layer_residual_quantiles()` should be used before population scaling or else \nthe transformation will make the results uninterpretable. \n\nWe wish, now, to predict the 7-day ahead death counts with lagged case rates and death\nrates, along with some extra behaviourial predictors. Namely, we will use survey data\nfrom [COVID-19 Trends and Impact Survey](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/fb-survey.html#behavior-indicators).\n\nThe survey data provides the estimated percentage of people who wore a mask for \nmost or all of the time while in public in the past 7 days and the estimated \npercentage of respondents who reported that all or most people they encountered \nin public in the past 7 days maintained a distance of at least 6 feet. \n\nState-wise population data from the 2019 U.S. Census is included in this package\nand will be used in `layer_population_scaling()`. \n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-6_1f1563f96f3033d428f64b4cf1d9346e'}\n\n```{.r .cell-code}\nbehav_ind_mask <- covidcast(\n  data_source = \"fb-survey\",\n  signals = \"smoothed_wwearing_mask_7d\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  fetch() %>%\n  select(geo_value, time_value, masking = value)\n\nbehav_ind_distancing <- covidcast(\n  data_source = \"fb-survey\",\n  signals = \"smoothed_wothers_distanced_public\",\n  time_type = \"day\",\n  geo_type = \"state\",\n  time_values = epirange(20210604, 20211231),\n  geo_values = geos\n) %>%\n  fetch() %>%\n  select(geo_value, time_value, distancing = value)\n\npop_dat <- state_census %>% select(abbr, pop)\n\nbehav_ind <- behav_ind_mask %>%\n  full_join(behav_ind_distancing, by = c(\"geo_value\", \"time_value\"))\n```\n:::\n\n\nRather than using raw mask-wearing / social-distancing metrics, for the sake\nof illustration, we'll convert both into categorical predictors.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-7_c09f59f7038a72e6682dd04a34af3d74'}\n::: {.cell-output-display}\n![](preprocessing-and-models_files/figure-html/unnamed-chunk-7-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\nWe will take a subset of death rate and case rate data from the built-in dataset \n`case_death_rate_subset`.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-8_9e6862f9e2540929103610d1df478a7c'}\n\n```{.r .cell-code}\njhu <- filter(\n  case_death_rate_subset,\n  time_value >= \"2021-06-04\",\n  time_value <= \"2021-12-31\",\n  geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\n)\n```\n:::\n\n\nPreprocessing steps will again rely on functions from the `epipredict` package as well\nas the `recipes` package.\nThere are also many functions in the `recipes` package that allow for \n[scalar transformations](https://recipes.tidymodels.org/reference/#step-functions-individual-transformations),\nsuch as log transformations and data centering. In our case, we will \ncenter the numerical predictors to allow for a more meaningful interpretation of the \nintercept. \n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-9_242151d710ac148de7d63cdcbeba304d'}\n\n```{.r .cell-code}\njhu <- jhu %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  left_join(behav_ind, by = c(\"geo_value\", \"time_value\")) %>%\n  as_epi_df()\n\nr <- epi_recipe(jhu) %>%\n  add_role(geo_value_factor, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%\n  step_mutate(\n    masking = cut_number(masking, 5),\n    distancing = cut_number(distancing, 5)\n  ) %>%\n  step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%\n  step_center(contains(\"lag\"), role = \"predictor\") %>%\n  step_epi_naomit()\n```\n:::\n\n\nAs a sanity check we can examine the structure of the training data:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-10_739fbd74ccf10a28db2967235256c879'}\n\n```{.r .cell-code}\nglimpse(slice_sample(bake(prep(r, jhu), jhu), n = 6))\n#> Rows: 6\n#> Columns: 17\n#> $ time_value          <date> 2021-09-18, 2021-08-31, 2021-11-22, 2021-10-20…\n#> $ geo_value           <chr> \"nj\", \"fl\", \"ca\", \"nj\", \"ca\", \"ny\"\n#> $ case_rate           <dbl> 25.186325, 96.305747, 13.121581, 13.638572, 3.0…\n#> $ death_rate          <dbl> 0.2058652, 1.2088092, 0.2286116, 0.2090819, 0.0…\n#> $ masking             <fct> \"(63.9,69.7]\", \"(63.9,69.7]\", \"(69.7,85]\", \"(60…\n#> $ distancing          <fct> \"(19.8,21.1]\", \"(19.8,21.1]\", \"(27,43]\", \"(21.1…\n#> $ geo_value_factor_fl <dbl> 0, 1, 0, 0, 0, 0\n#> $ geo_value_factor_nj <dbl> 1, 0, 0, 1, 0, 0\n#> $ geo_value_factor_ny <dbl> 0, 0, 0, 0, 0, 1\n#> $ geo_value_factor_tx <dbl> 0, 0, 0, 0, 0, 0\n#> $ lag_0_case_rate     <dbl> -1.755337, 69.364085, -13.820081, -13.303090, -…\n#> $ lag_7_case_rate     <dbl> -3.001787, 70.895638, -13.963054, -8.386449, -2…\n#> $ lag_14_case_rate    <dbl> -3.952305, 86.799466, -11.321320, -7.424673, -2…\n#> $ lag_0_death_rate    <dbl> -0.0760084, 0.9269356, -0.0532620, -0.0727917, …\n#> $ lag_7_death_rate    <dbl> -0.1017415, 0.7645779, -0.0652369, -0.1033498, …\n#> $ lag_14_death_rate   <dbl> -0.1242580, 0.3511244, -0.0880980, -0.0534919, …\n#> $ ahead_7_death_rate  <dbl> 0.2267734, 1.5854529, 0.1857923, 0.2348150, 0.0…\n```\n:::\n\n\nBefore directly predicting the results, we need to add postprocessing layers to\nobtain the death counts instead of death rates. Note that the rates used so\nfar are \"per 100K people\" rather than \"per person\". We'll also use quantile\nregression with the `quantile_reg` engine rather than ordinary least squares\nto create median predictions and a 90% prediction interval.\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-11_f526e651b5603741d94f6c45a1c7cd09'}\n\n```{.r .cell-code}\nf <- frosting() %>%\n  layer_predict() %>%\n  layer_add_target_date(\"2022-01-07\") %>%\n  layer_threshold(.pred, lower = 0) %>%\n  layer_quantile_distn() %>%\n  layer_naomit(.pred) %>%\n  layer_population_scaling(\n    .pred, .pred_distn,\n    df = pop_dat,\n    rate_rescaling = 1e5,\n    by = c(\"geo_value\" = \"abbr\"),\n    df_pop_col = \"pop\"\n  )\n\nwf <- epi_workflow(r, quantile_reg(tau = c(.05, .5, .95))) %>%\n  fit(jhu) %>%\n  add_frosting(f)\n\nlatest <- get_test_data(recipe = r, x = jhu)\np <- predict(wf, latest)\np\n#> An `epi_df` object, 5 x 7 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25.791826\n#> \n#> # A tibble: 5 × 7\n#>   geo_value time_value               .pred target_date         .pred_distn\n#> * <chr>     <date>                  <dist> <date>                   <dist>\n#> 1 ca        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07  [0.25, 0.75]<q-rng>\n#> 2 fl        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07  [0.25, 0.75]<q-rng>\n#> 3 nj        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07  [0.25, 0.75]<q-rng>\n#> 4 ny        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07  [0.25, 0.75]<q-rng>\n#> 5 tx        2021-12-31 [0.05, 0.95]<q-rng> 2022-01-07  [0.25, 0.75]<q-rng>\n#> # ℹ 2 more variables: .pred_scaled <dist>, .pred_distn_scaled <dist>\n```\n:::\n\n\nThe columns marked `*_scaled` have been rescaled to the correct units, in this\ncase `deaths` rather than deaths per 100K people (these remain in `.pred`).\n\nTo look at the prediction intervals:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-12_1b69254f581c486321bf528a595668f6'}\n\n```{.r .cell-code}\np %>%\n  select(geo_value, target_date, .pred_scaled, .pred_distn_scaled) %>%\n  mutate(.pred_distn_scaled = nested_quantiles(.pred_distn_scaled)) %>%\n  unnest(.pred_distn_scaled) %>%\n  pivot_wider(names_from = tau, values_from = q)\n#> # A tibble: 5 × 5\n#>   geo_value target_date        .pred_scaled `0.25` `0.75`\n#>   <chr>     <date>                   <dist>  <dbl>  <dbl>\n#> 1 ca        2022-01-07  [0.05, 0.95]<q-rng>   48.8   94.0\n#> 2 fl        2022-01-07  [0.05, 0.95]<q-rng>   48.4  104. \n#> 3 nj        2022-01-07  [0.05, 0.95]<q-rng>   45.5   68.7\n#> 4 ny        2022-01-07  [0.05, 0.95]<q-rng>  108.   163. \n#> 5 tx        2022-01-07  [0.05, 0.95]<q-rng>   68.6  107.\n```\n:::\n\n\n\nLast but not least, let's take a look at the regression fit and check the \ncoefficients:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-13_5330a6080778bb1287e047d0a8462825'}\n\n```\n#> Call:\n#> quantreg::rq(formula = ..y ~ ., tau = ~c(0.05, 0.5, 0.95), data = data, \n#>     na.action = stats::na.omit, method = \"br\", model = FALSE)\n#> \n#> Coefficients:\n#>                        tau= 0.05     tau= 0.50    tau= 0.95\n#> (Intercept)          0.210811625  0.2962574475  0.417583265\n#> geo_value_factor_fl  0.032085820  0.0482361119  0.171126713\n#> geo_value_factor_nj  0.007313762 -0.0033797953 -0.025251865\n#> geo_value_factor_ny -0.001489163 -0.0199485947 -0.032635584\n#> geo_value_factor_tx  0.029077485  0.0391980273  0.071961515\n#> lag_0_case_rate     -0.001636588 -0.0011625693 -0.001430622\n#> lag_7_case_rate      0.004700752  0.0057822095  0.006912655\n#> lag_14_case_rate     0.001715816  0.0004224753  0.003448733\n#> lag_0_death_rate     0.462341754  0.5274192012  0.164856372\n#> lag_7_death_rate    -0.007368501  0.1132903956  0.172687438\n#> lag_14_death_rate   -0.072500707 -0.0270474349  0.181279299\n#> \n#> Degrees of freedom: 950 total; 939 residual\n```\n:::\n\n\n## Classification\n\nSometimes it is preferable to create a predictive model for surges or upswings\nrather than for raw values. In this case,\nthe target is to predict if the future will have increased case rates (denoted `up`),\ndecreased case rates (`down`), or flat case rates (`flat`) relative to the current\nlevel. Such models may be \nreferred to as \"hotspot prediction models\". We will follow the analysis \nin [McDonald, Bien, Green, Hu, et al.](#references) but extend the application\nto predict three categories instead of two. \n\nHotspot prediction uses a categorical outcome variable defined in terms of the \nrelative change of $Y_{\\ell, t+a}$ compared to $Y_{\\ell, t}$. \nWhere $Y_{\\ell, t}$ denotes the case rates in location $\\ell$ at time $t$. \nWe define the response variables as follows:\n\n$$\n Z_{\\ell, t}=\n    \\begin{cases}\n      \\text{up}, & \\text{if}\\ Y^{\\Delta}_{\\ell, t} > 0.25 \\\\ \n      \\text{down}, & \\text{if}\\  Y^{\\Delta}_{\\ell, t} < -0.20\\\\\n      \\text{flat}, & \\text{otherwise}\n    \\end{cases}\n$$\n\nwhere $Y^{\\Delta}_{\\ell, t} = (Y_{\\ell, t}- Y_{\\ell, t-7})\\ /\\ (Y_{\\ell, t-7})$. \nWe say location $\\ell$ is a hotspot at time $t$ when $Z_{\\ell,t}$ is \n`up`, meaning the number of newly reported cases over the past 7 days has \nincreased by at least 25% compared to the preceding week. When $Z_{\\ell,t}$ \nis categorized as `down`, it suggests that there has been at least a 20% \ndecrease in newly reported cases over the past 7 days (a 20% decrease is the inverse of a 25% increase). Otherwise, we will \nconsider the trend to be `flat`. \n\nThe expression of the multinomial regression we will use is as follows:\n$$\n\\pi_{j}(x) = \\text{Pr}(Z_{\\ell,t} = j|x) = \\frac{e^{g_j(x)}}{1 + \\sum_{k=0}^2 g_j(x) }\n$$\nwhere $j$ is either down, flat, or up\n\n$$\n\\begin{aligned}\ng_{\\text{down}}(x) &= 0,\\\\\ng_{\\text{flat}}(x) &= \n\\log\\left(\\frac{Pr(Z_{\\ell,t}=\\text{flat}|x)}{Pr(Z_{\\ell,t}=\\text{down}|x)}\\right) = \n\\beta_{10} + \\beta_{11}t + \\delta_{10} s_{\\text{state}_1} +\n\\delta_{11} s_{\\text{state}_2} + \\cdots \\nonumber \\\\\n&\\quad +\\ \\beta_{12} Y^{\\Delta}_{\\ell, t} +\n\\beta_{13} Y^{\\Delta}_{\\ell, t-7}, \\\\\ng_{\\text{flat}}(x) &= \\log\\left(\\frac{Pr(Z_{\\ell,t}=\\text{up}|x)}{Pr(Z_{\\ell,t}=\\text{down}|x)}\\right) = \n\\beta_{20} + \\beta_{21}t + \\delta_{20} s_{\\text{state}_1} +\n\\delta_{21} s_{\\text{state}_2} + \\cdots \\nonumber \\\\\n&\\quad +\\ \\beta_{22} Y^{\\Delta}_{\\ell, t} +\n\\beta_{23} Y^{\\Delta}_{\\ell, t-7}.\n\\end{aligned}\n$$\n\n\nPreprocessing steps are similar to the previous models with an additional step \nof categorizing the response variables. Again, we will use a subset of death rate and case rate data from our built-in dataset \n`case_death_rate_subset`.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-14_76c147c3b47a5cd0f2549be0f8a7d6c5'}\n\n```{.r .cell-code}\njhu <- case_death_rate_subset %>%\n  dplyr::filter(\n    time_value >= \"2021-06-04\",\n    time_value <= \"2021-12-31\",\n    geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")\n  ) %>%\n  mutate(geo_value_factor = as.factor(geo_value)) %>%\n  as_epi_df()\n\nr <- epi_recipe(jhu) %>%\n  add_role(time_value, new_role = \"predictor\") %>%\n  step_dummy(geo_value_factor) %>%\n  step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(case_rate, ahead = 7, role = \"predictor\") %>%\n  step_mutate(\n    pct_diff_ahead = case_when(\n      lag_7_case_rate == 0 ~ 0,\n      TRUE ~ (ahead_7_case_rate - lag_0_case_rate) / lag_0_case_rate\n    ),\n    pct_diff_wk1 = case_when(\n      lag_7_case_rate == 0 ~ 0,\n      TRUE ~ (lag_0_case_rate - lag_7_case_rate) / lag_7_case_rate\n    ),\n    pct_diff_wk2 = case_when(\n      lag_14_case_rate == 0 ~ 0,\n      TRUE ~ (lag_7_case_rate - lag_14_case_rate) / lag_14_case_rate\n    )\n  ) %>%\n  step_mutate(\n    response = case_when(\n      pct_diff_ahead < -0.20 ~ \"down\",\n      pct_diff_ahead > 0.25 ~ \"up\",\n      TRUE ~ \"flat\"\n    ),\n    role = \"outcome\"\n  ) %>%\n  step_rm(\n    death_rate, case_rate, lag_0_case_rate, lag_7_case_rate,\n    lag_14_case_rate, ahead_7_case_rate, pct_diff_ahead\n  ) %>%\n  step_epi_naomit()\n```\n:::\n\n\nWe will fit the multinomial regression and examine the predictions:\n\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-15_223f4e8fe4791174dee2dc2e1a58cf5f'}\n\n```{.r .cell-code}\nwf <- epi_workflow(r, parsnip::multinom_reg()) %>%\n  fit(jhu)\n\nlatest <- get_test_data(recipe = r, x = jhu)\npredict(wf, latest) %>% filter(!is.na(.pred_class))\n#> An `epi_df` object, 5 x 3 with metadata:\n#> * geo_type  = state\n#> * time_type = day\n#> * as_of     = 2022-05-31 12:08:25.791826\n#> \n#> # A tibble: 5 × 3\n#>   geo_value time_value .pred_class\n#> * <chr>     <date>     <fct>      \n#> 1 ca        2021-12-31 up         \n#> 2 fl        2021-12-31 up         \n#> 3 nj        2021-12-31 up         \n#> 4 ny        2021-12-31 up         \n#> 5 tx        2021-12-31 flat\n```\n:::\n\n\nWe can also look at the estimated coefficients and model summary information:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-16_63e9f9076be6dc14c80f11697df94bc7'}\n\n```{.r .cell-code}\nextract_fit_engine(wf)\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept)   time_value geo_value_factor_fl geo_value_factor_nj\n#> flat   -58.11177  0.003162471          -0.5978151            1.350320\n#> up      46.45080 -0.002429847          -0.4682080            1.572085\n#>      geo_value_factor_ny geo_value_factor_tx pct_diff_wk1 pct_diff_wk2\n#> flat            3.113677          -0.3010305     1.263089     3.610543\n#> up              3.172692          -0.2505232     2.194646     4.266267\n#> \n#> Residual Deviance: 1529.929 \n#> AIC: 1561.929\n```\n:::\n\n\nOne could also use a formula in `epi_recipe()` to achieve the same results as \nabove. However, only one of `add_formula()`, `add_recipe()`, or \n`workflow_variables()` can be specified. For the purpose of demonstrating \n`add_formula` rather than `add_recipe`, we will `prep` and `bake` our recipe to\nreturn a `data.frame` that could be used for model fitting.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-17_a11cc40f94ac0084106c36251055bc68'}\n\n```{.r .cell-code}\nb <- bake(prep(r, jhu), jhu)\n\nepi_workflow() %>%\n  add_formula(response ~ geo_value + time_value + pct_diff_wk1 + pct_diff_wk2) %>%\n  add_model(parsnip::multinom_reg()) %>%\n  fit(data = b)\n#> ══ Workflow [trained] ═══════════════════════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: multinom_reg()\n#> \n#> ── Preprocessor ─────────────────────────────────────────────────────────────\n#> response ~ geo_value + time_value + pct_diff_wk1 + pct_diff_wk2\n#> \n#> ── Model ────────────────────────────────────────────────────────────────────\n#> Call:\n#> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n#> \n#> Coefficients:\n#>      (Intercept) geo_valuefl geo_valuenj geo_valueny geo_valuetx\n#> flat   -58.11158  -0.5978159    1.350325    3.113684  -0.3010308\n#> up      46.45071  -0.4682087    1.572090    3.172698  -0.2505236\n#>        time_value pct_diff_wk1 pct_diff_wk2\n#> flat  0.003162461     1.263093     3.610536\n#> up   -0.002429839     2.194649     4.266259\n#> \n#> Residual Deviance: 1529.929 \n#> AIC: 1561.929\n```\n:::\n\n\n## Benefits of Lagging and Leading in `epipredict`\n\nThe `step_epi_ahead` and `step_epi_lag` functions in the `epipredict` package\nis handy for creating correct lags and leads for future predictions. \n\nLet's start with a simple dataset and preprocessing:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-18_be8f9ca661c2642872fa0455a831f1f0'}\n\n```{.r .cell-code}\nex <- filter(\n  case_death_rate_subset,\n  time_value >= \"2021-12-01\",\n  time_value <= \"2021-12-31\",\n  geo_value == \"ca\"\n)\n\ndim(ex)\n#> [1] 31  4\n```\n:::\n\n\nWe want to predict death rates on 2022-01-07, which is 7 days ahead of the \nlatest available date in our dataset. \n\nWe will compare two methods of trying to create lags and leads:\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-19_e623fb913d1272d0638e315d665c0646'}\n\n```{.r .cell-code}\np1 <- epi_recipe(ex) %>%\n  step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%\n  step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%\n  step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%\n  step_epi_naomit() %>%\n  prep()\n\nb1 <- bake(p1, ex)\nb1\n#> # A tibble: 17 × 11\n#>   time_value geo_value case_rate death_rate lag_0_case_rate lag_7_case_rate\n#>   <date>     <chr>         <dbl>      <dbl>           <dbl>           <dbl>\n#> 1 2021-12-15 ca             15.8      0.157            15.8            18.0\n#> 2 2021-12-16 ca             16.3      0.155            16.3            17.4\n#> 3 2021-12-17 ca             16.9      0.158            16.9            17.4\n#> 4 2021-12-18 ca             17.6      0.164            17.6            17.2\n#> 5 2021-12-19 ca             19.1      0.165            19.1            16.3\n#> 6 2021-12-20 ca             20.6      0.164            20.6            16.0\n#> # ℹ 11 more rows\n#> # ℹ 5 more variables: lag_14_case_rate <dbl>, lag_0_death_rate <dbl>, …\n\n\np2 <- epi_recipe(ex) %>%\n  step_mutate(\n    lag0case_rate = lag(case_rate, 0),\n    lag7case_rate = lag(case_rate, 7),\n    lag14case_rate = lag(case_rate, 14),\n    lag0death_rate = lag(death_rate, 0),\n    lag7death_rate = lag(death_rate, 7),\n    lag14death_rate = lag(death_rate, 14),\n    ahead7death_rate = lead(death_rate, 7)\n  ) %>%\n  step_epi_naomit() %>%\n  prep()\n\nb2 <- bake(p2, ex)\nb2\n#> # A tibble: 10 × 11\n#>   time_value geo_value case_rate death_rate lag0case_rate lag7case_rate\n#>   <date>     <chr>         <dbl>      <dbl>         <dbl>         <dbl>\n#> 1 2021-12-15 ca             15.8      0.157          15.8          18.0\n#> 2 2021-12-16 ca             16.3      0.155          16.3          17.4\n#> 3 2021-12-17 ca             16.9      0.158          16.9          17.4\n#> 4 2021-12-18 ca             17.6      0.164          17.6          17.2\n#> 5 2021-12-19 ca             19.1      0.165          19.1          16.3\n#> 6 2021-12-20 ca             20.6      0.164          20.6          16.0\n#> # ℹ 4 more rows\n#> # ℹ 5 more variables: lag14case_rate <dbl>, lag0death_rate <dbl>, …\n```\n:::\n\n\nNotice the difference in number of rows `b1` and `b2` returns. This is because \nthe second version, the one that doesn't use `step_epi_ahead` and `step_epi_lag`,\nhas omitted dates compared to the one that used the `epipredict` functions.\n\n::: {.cell layout-align=\"center\" hash='preprocessing-and-models_cache/html/unnamed-chunk-20_e805daad3d3a3b677172f8bc9e57f277'}\n\n```{.r .cell-code}\ndates_used_in_training1 <- b1 %>%\n  select(-ahead_7_death_rate) %>%\n  na.omit() %>%\n  select(time_value)\ndates_used_in_training1\n#> # A tibble: 17 × 1\n#>   time_value\n#>   <date>    \n#> 1 2021-12-15\n#> 2 2021-12-16\n#> 3 2021-12-17\n#> 4 2021-12-18\n#> 5 2021-12-19\n#> 6 2021-12-20\n#> # ℹ 11 more rows\n\ndates_used_in_training2 <- b2 %>%\n  select(-ahead7death_rate) %>%\n  na.omit() %>%\n  select(time_value)\ndates_used_in_training2\n#> # A tibble: 10 × 1\n#>   time_value\n#>   <date>    \n#> 1 2021-12-15\n#> 2 2021-12-16\n#> 3 2021-12-17\n#> 4 2021-12-18\n#> 5 2021-12-19\n#> 6 2021-12-20\n#> # ℹ 4 more rows\n```\n:::\n\n\nThe model that is trained based on the `{recipes}` functions will predict 7 days ahead from \n2021-12-24\ninstead of 7 days ahead from 2021-12-31.\n\n## References\n\nMcDonald, Bien, Green, Hu, et al. \"Can auxiliary indicators improve COVID-19 \nforecasting and hotspot prediction?.\" Proceedings of the National Academy of \nSciences 118.51 (2021): e2111453118. [doi:10.1073/pnas.2111453118](\nhttps://doi.org/10.1073/pnas.2111453118)\n\n## Attribution\n\nThis vignette contains a modified part of the [COVID-19 Data Repository by the\nCenter for Systems Science and Engineering (CSSE) at Johns Hopkins\nUniversity](https://github.com/CSSEGISandData/COVID-19) as [republished in the\nCOVIDcast Epidata\nAPI.](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html).\nSee the COVIDcast Epidata API documentation for its modifications, and the code\nabove for further modifications. This data set is licensed under the terms of\nthe [Creative Commons Attribution 4.0 International\nlicense](https://creativecommons.org/licenses/by/4.0/) by the Johns Hopkins\nUniversity on behalf of its Center for Systems Science in Engineering. Copyright\nJohns Hopkins University 2020.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}